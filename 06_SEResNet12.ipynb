{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_SEResNet12.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "612VTm8MGcIg",
        "6i4QGn8GlsT8",
        "Pzp3OVaulzAf"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "65e0869e3c7d407ab8200b8eb8921dd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5825216817a64712aca591da40dd37c5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f7d9a5411f314235b9c031cd25c04675",
              "IPY_MODEL_21f0d8e02ee840dbae3a0bbc0fc6ee05",
              "IPY_MODEL_1f1664413adc4ddeb1d22f087bc0ec22"
            ]
          }
        },
        "5825216817a64712aca591da40dd37c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7d9a5411f314235b9c031cd25c04675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_efcf46b526a34d088c4440390da3d6e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_befe68a321e54f98a51e0529649409dd"
          }
        },
        "21f0d8e02ee840dbae3a0bbc0fc6ee05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_340b2a60b8e74777bede41ab6ac52a68",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 196,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 196,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3879d6b781ae40019f1bd819e1867438"
          }
        },
        "1f1664413adc4ddeb1d22f087bc0ec22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a55320738e5c467f918377f365b0dae5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 196/196 [00:20&lt;00:00,  9.75it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6305da855bf649dd964d5978aa0104f6"
          }
        },
        "efcf46b526a34d088c4440390da3d6e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "befe68a321e54f98a51e0529649409dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "340b2a60b8e74777bede41ab6ac52a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3879d6b781ae40019f1bd819e1867438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a55320738e5c467f918377f365b0dae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6305da855bf649dd964d5978aa0104f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joyonclear/ResNet/blob/main/06_SEResNet12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "verYUSWTgmr4"
      },
      "source": [
        "# 구글 드라이브 마운트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "638QgAgAginq",
        "outputId": "d72fd339-d104-4768-f5f2-b259719367f5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "drive_path = \"/content/drive/MyDrive/Colab_Notebooks/pruning_result/\"\n",
        "!ls /content/drive/MyDrive/Colab_Notebooks/pruning_result/"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "04_SEResNet12.pth  06_SEResNet12.pth  model_best02.pth\tmodel_best.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grc-bqbumwId"
      },
      "source": [
        "# Library Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jxGjpNB8_VJ",
        "outputId": "49210102-f1c7-434b-f5d9-c0528bf46b8d"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "import numpy as np\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.5.3-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCRtZPFlhhgw"
      },
      "source": [
        "# ResNet Basic Block Design"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYLGwlX59IyU"
      },
      "source": [
        "# short-cut 기반 네트워크를 사용하기 위해 만드는 sub layer module\n",
        "# https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py 코드 참고해서 이해하면 좋음\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    # expansion = 1 -> bottleneck layer를 사용하지 않겠다.\n",
        "    expansion = 1\n",
        "    \n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        # 보통 kernel=7, padding=3 이지만 CIFAR-10은 32*32의 작은 이미지라서 이러면 처음에 손실이 너무 커서 오히려 안좋음\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.linear1 = nn.Linear(planes, planes//4)\n",
        "        self.linear2 = nn.Linear(planes//4, planes)\n",
        "        \n",
        "    # stride 1 아니거나 입력과 출력이 다르면 shortcut이라는 모델을 하나 만듦\n",
        "    # kernel=1 -> 동일한 size의 출력으로 convolution 진행 및 정규화\n",
        "        self.shortcut = nn.Sequential() \n",
        "        if stride != 1 or in_planes != self.expansion*planes:  \n",
        "            self.shortcut = nn.Sequential(nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False), \n",
        "                                            nn.BatchNorm2d(self.expansion*planes)) \n",
        "\n",
        "    # ResNet Basic Block\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        \n",
        "        squeeze = out.mean(dim=(-2, -1))    # Global Average Pooling\n",
        "        excitation = self.linear1(squeeze)\n",
        "        excitation = F.relu(excitation)\n",
        "        excitation = self.linear2(excitation)\n",
        "        excitation = F.sigmoid(excitation)\n",
        "        excitation = excitation.unsqueeze(dim=2).unsqueeze(dim=3)\n",
        "        scale = out * excitation\n",
        "        scale += self.shortcut(x)\n",
        "        scale = F.relu(scale)\n",
        "        return scale\n",
        "        '''\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "        '''"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck2gO9pjRbdp"
      },
      "source": [
        "# Squeeze and Excitation Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5C1RUcrQsRb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a7801bf-ce01-498b-9aeb-8f9bf93a80c9"
      },
      "source": [
        "# 처음 레이어 생성\n",
        "ch = 64\n",
        "feature_maps = torch.rand(10, ch, 32, 32)\n",
        "#print(feature_maps)\n",
        "print(feature_maps.shape)\n",
        "#print(type(len(feature_maps[0])))\n",
        "\n",
        "\n",
        "# 글로벌 풀링\n",
        "feature_vector = feature_maps.mean(dim=(-2, -1))  # or dim=(2, 3)\n",
        "#print('\\nfeature_vector result\\n',feature_vector)\n",
        "print(feature_vector.shape)\n",
        "\n",
        "# FCL 앞 뒤\n",
        "fc = nn.Linear(ch, 5)\n",
        "fc2 = nn.Linear(5, ch)\n",
        "kk = fc(feature_vector)\n",
        "print(kk.shape)\n",
        "xx = fc2(kk)\n",
        "print(xx.shape)\n",
        "\n",
        "# 레이어 재생성용\n",
        "#GAP = nn.AdaptiveAvgPool2d((1, 1)) # target output shape\n",
        "#feature_vector = GAP(xx)\n",
        "feature_vector = xx.unsqueeze(dim=2).unsqueeze(dim=3)\n",
        "print(feature_vector.shape)\n",
        "\n",
        "# 스퀴즈 곱하기\n",
        "tt = feature_maps*feature_vector\n",
        "#print(tt)\n",
        "print(tt.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 64, 32, 32])\n",
            "torch.Size([10, 64])\n",
            "torch.Size([10, 5])\n",
            "torch.Size([10, 64])\n",
            "torch.Size([10, 64, 1, 1])\n",
            "torch.Size([10, 64, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31WpmqaQiCBE"
      },
      "source": [
        "# ResNet Architecture Design"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30zFwi53g29D"
      },
      "source": [
        "# 만들어진 BasicBlock 을 기반으로 network design\n",
        "# nn.Conv2d의 갯수가 12개가 되도록 하면 됨.(단 shortcut 제외 shortcut의 경우에는 conv layer 개수 셀 때 제외됨.(linear transform으로 취급하는 경우가 많음))\n",
        "# https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py 코드 참고해서 이해하면 좋음\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 192, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 256, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(256*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO3OW8HXkU9f"
      },
      "source": [
        "# ResNet12 Design"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OCmVxZmLqWn",
        "outputId": "72787602-0fb2-4fd2-8185-22c720279e93"
      },
      "source": [
        "def ResNet12():\n",
        "    return ResNet(BasicBlock, [1, 1, 1, 2])\n",
        "\n",
        "net = ResNet12()\n",
        "input = torch.randn(10, 3, 32, 32)\n",
        "# torch summary를 통한 conv net, output shape 등에 대한 확인\n",
        "\n",
        "summary(net, input_size=input.shape)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ResNet                                   --                        --\n",
              "├─Conv2d: 1-1                            [10, 64, 32, 32]          1,728\n",
              "├─BatchNorm2d: 1-2                       [10, 64, 32, 32]          128\n",
              "├─Sequential: 1-3                        [10, 64, 32, 32]          --\n",
              "│    └─BasicBlock: 2-1                   [10, 64, 32, 32]          --\n",
              "│    │    └─Conv2d: 3-1                  [10, 64, 32, 32]          36,864\n",
              "│    │    └─BatchNorm2d: 3-2             [10, 64, 32, 32]          128\n",
              "│    │    └─Conv2d: 3-3                  [10, 64, 32, 32]          36,864\n",
              "│    │    └─BatchNorm2d: 3-4             [10, 64, 32, 32]          128\n",
              "│    │    └─Linear: 3-5                  [10, 16]                  1,040\n",
              "│    │    └─Linear: 3-6                  [10, 64]                  1,088\n",
              "│    │    └─Sequential: 3-7              [10, 64, 32, 32]          --\n",
              "├─Sequential: 1-4                        [10, 128, 16, 16]         --\n",
              "│    └─BasicBlock: 2-2                   [10, 128, 16, 16]         --\n",
              "│    │    └─Conv2d: 3-8                  [10, 128, 16, 16]         73,728\n",
              "│    │    └─BatchNorm2d: 3-9             [10, 128, 16, 16]         256\n",
              "│    │    └─Conv2d: 3-10                 [10, 128, 16, 16]         147,456\n",
              "│    │    └─BatchNorm2d: 3-11            [10, 128, 16, 16]         256\n",
              "│    │    └─Linear: 3-12                 [10, 32]                  4,128\n",
              "│    │    └─Linear: 3-13                 [10, 128]                 4,224\n",
              "│    │    └─Sequential: 3-14             [10, 128, 16, 16]         8,448\n",
              "├─Sequential: 1-5                        [10, 192, 8, 8]           --\n",
              "│    └─BasicBlock: 2-3                   [10, 192, 8, 8]           --\n",
              "│    │    └─Conv2d: 3-15                 [10, 192, 8, 8]           221,184\n",
              "│    │    └─BatchNorm2d: 3-16            [10, 192, 8, 8]           384\n",
              "│    │    └─Conv2d: 3-17                 [10, 192, 8, 8]           331,776\n",
              "│    │    └─BatchNorm2d: 3-18            [10, 192, 8, 8]           384\n",
              "│    │    └─Linear: 3-19                 [10, 48]                  9,264\n",
              "│    │    └─Linear: 3-20                 [10, 192]                 9,408\n",
              "│    │    └─Sequential: 3-21             [10, 192, 8, 8]           24,960\n",
              "├─Sequential: 1-6                        [10, 256, 4, 4]           --\n",
              "│    └─BasicBlock: 2-4                   [10, 256, 4, 4]           --\n",
              "│    │    └─Conv2d: 3-22                 [10, 256, 4, 4]           442,368\n",
              "│    │    └─BatchNorm2d: 3-23            [10, 256, 4, 4]           512\n",
              "│    │    └─Conv2d: 3-24                 [10, 256, 4, 4]           589,824\n",
              "│    │    └─BatchNorm2d: 3-25            [10, 256, 4, 4]           512\n",
              "│    │    └─Linear: 3-26                 [10, 64]                  16,448\n",
              "│    │    └─Linear: 3-27                 [10, 256]                 16,640\n",
              "│    │    └─Sequential: 3-28             [10, 256, 4, 4]           49,664\n",
              "│    └─BasicBlock: 2-5                   [10, 256, 4, 4]           --\n",
              "│    │    └─Conv2d: 3-29                 [10, 256, 4, 4]           589,824\n",
              "│    │    └─BatchNorm2d: 3-30            [10, 256, 4, 4]           512\n",
              "│    │    └─Conv2d: 3-31                 [10, 256, 4, 4]           589,824\n",
              "│    │    └─BatchNorm2d: 3-32            [10, 256, 4, 4]           512\n",
              "│    │    └─Linear: 3-33                 [10, 64]                  16,448\n",
              "│    │    └─Linear: 3-34                 [10, 256]                 16,640\n",
              "│    │    └─Sequential: 3-35             [10, 256, 4, 4]           --\n",
              "├─Linear: 1-7                            [10, 10]                  2,570\n",
              "==========================================================================================\n",
              "Total params: 3,246,122\n",
              "Trainable params: 3,246,122\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 2.09\n",
              "==========================================================================================\n",
              "Input size (MB): 0.12\n",
              "Forward/backward pass size (MB): 56.45\n",
              "Params size (MB): 12.98\n",
              "Estimated Total Size (MB): 69.56\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "612VTm8MGcIg"
      },
      "source": [
        "# DataSet Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUvtY4zPBb4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "65e0869e3c7d407ab8200b8eb8921dd6",
            "5825216817a64712aca591da40dd37c5",
            "f7d9a5411f314235b9c031cd25c04675",
            "21f0d8e02ee840dbae3a0bbc0fc6ee05",
            "1f1664413adc4ddeb1d22f087bc0ec22",
            "efcf46b526a34d088c4440390da3d6e0",
            "befe68a321e54f98a51e0529649409dd",
            "340b2a60b8e74777bede41ab6ac52a68",
            "3879d6b781ae40019f1bd819e1867438",
            "a55320738e5c467f918377f365b0dae5",
            "6305da855bf649dd964d5978aa0104f6"
          ]
        },
        "outputId": "444ddd39-f2ba-4bbe-940d-0f4780a8a9ef"
      },
      "source": [
        "#cifar10 의 데이터의 경우 torchvision.datasets 를 사용해 \n",
        "#데이터를 불러오고 해당하는 데이터를 torch 에서 사용가능하게 dataloader 에 넣어주는 작업을 거칠 예정\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "                                [\n",
        "                                  transforms.RandomCrop(32, padding=4),\n",
        "                                  transforms.RandomHorizontalFlip(),\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),                                \n",
        "                                 ]\n",
        "                               )\n",
        "\n",
        "\n",
        "# train_data, test_data 를 torchvision에서 제공해주는 datasets.CIFAR10 으로 읽어온다.\n",
        "# 읽어온 결과는 dataset으로 저장되며 이 dataset은 dataloader를 거쳐서 학습에 사용된다.\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root = \"./data\", train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.CIFAR10(root = \"./data\", train=False, transform=transform, download=True)\n",
        "\n",
        "# 데이터의 총 개수 해당 데이터에선 50000개의 데이터가 (img, label)의 tuple 형식으로 저장 되어있다.\n",
        "print(\"train_dataset의 개수 : \", len(train_dataset))\n",
        "print(\"test_dataset의 개수 : \", len(test_dataset))\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
        "                         shuffle=False, num_workers=2)\n",
        "\n",
        "# data를 배치 단위로 불러오는 법 test\n",
        "# for 문이 loop를 다 돌면 1 epoch가 끝나는 형태\n",
        "# tqdm library를 사용해 현재 어느 iteration까지 진행되었는지 notebook 상에서 prograss bar 로 visualize가 가능\n",
        "for i, (data, target) in enumerate(tqdm(train_loader)):\n",
        "    if i == 0 :\n",
        "        print(\"batch data shape : \", data.shape)\n",
        "        print(\"batch data label : \", target)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "train_dataset의 개수 :  50000\n",
            "test_dataset의 개수 :  10000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65e0869e3c7d407ab8200b8eb8921dd6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/196 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch data shape :  torch.Size([256, 3, 32, 32])\n",
            "batch data label :  tensor([9, 3, 3, 1, 0, 4, 4, 7, 2, 1, 1, 2, 6, 5, 8, 7, 2, 0, 3, 2, 8, 5, 1, 5,\n",
            "        7, 0, 8, 5, 7, 7, 8, 0, 7, 1, 0, 4, 9, 0, 1, 8, 7, 9, 1, 7, 9, 8, 3, 3,\n",
            "        0, 9, 1, 8, 2, 4, 0, 7, 4, 1, 0, 5, 4, 6, 7, 1, 9, 1, 2, 9, 3, 0, 2, 0,\n",
            "        8, 8, 7, 1, 6, 5, 5, 2, 5, 2, 3, 4, 0, 2, 7, 2, 2, 2, 3, 5, 8, 3, 2, 4,\n",
            "        7, 8, 9, 2, 3, 2, 5, 5, 2, 3, 1, 0, 0, 1, 7, 4, 9, 5, 0, 4, 0, 2, 6, 0,\n",
            "        2, 1, 0, 0, 0, 6, 1, 2, 7, 1, 2, 9, 7, 2, 9, 5, 6, 8, 2, 5, 4, 2, 1, 3,\n",
            "        1, 4, 9, 9, 0, 5, 4, 6, 2, 9, 9, 3, 6, 1, 0, 5, 0, 6, 0, 8, 3, 1, 6, 9,\n",
            "        0, 5, 5, 4, 4, 2, 7, 0, 6, 2, 7, 4, 9, 0, 6, 1, 5, 9, 4, 5, 6, 5, 2, 5,\n",
            "        2, 2, 7, 6, 7, 2, 5, 9, 5, 8, 2, 4, 0, 9, 3, 6, 6, 9, 4, 2, 8, 8, 5, 9,\n",
            "        7, 7, 7, 6, 8, 8, 5, 1, 7, 4, 9, 3, 5, 5, 3, 8, 0, 7, 7, 4, 8, 4, 8, 9,\n",
            "        0, 3, 3, 2, 3, 0, 6, 8, 1, 2, 3, 0, 6, 9, 2, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i4QGn8GlsT8"
      },
      "source": [
        "# Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JT1IRh9l_iF"
      },
      "source": [
        "# batch_size의 predict와 label을 받으면 그 결과를 accuracy로 출력한다.\n",
        "def accuracy(predict, label, printable=False):\n",
        "  # 해당 연산이 연산의 계산그래프에 들어가면 안되기에 gradient 계산에서 제외한다.\n",
        "  with torch.no_grad():\n",
        "    # 각 row마다 predict의 추측값이 가장 높은 값의 index를 가지고 온다.(argmax 사용)\n",
        "    predicted = torch.argmax(predict.data, 1)\n",
        "    # 해당하는 predicted 값이 labels와 같은 값인지를 확인한다.\n",
        "    correct = (predicted == label).sum().item()\n",
        "    temp_acc = (100 * correct / predict.shape[0])\n",
        "    if printable:\n",
        "      print(f'Accuracy of the network on the test images (batch_size : {predict.shape[0]}): {temp_acc}%')\n",
        "    \n",
        "    return temp_acc"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pzp3OVaulzAf"
      },
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DZt1Gcnoiov"
      },
      "source": [
        "# validate function\n",
        "def validate(net, CEloss , test_loader):\n",
        "  # test data에 따라 검색하기\n",
        "  start_time = time.time()\n",
        "  \n",
        "  total_acc = []\n",
        "  total_loss = []\n",
        "\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  print(\"device : \", device)\n",
        "  assert device == \"cuda\"\n",
        "  # network를 device type 으로 변경\n",
        "  net.to(device)\n",
        "\n",
        "  for data, label in tqdm(test_loader):\n",
        "    # test data를 돌릴 때에는 gradinet 계산을 하면 안되기에 no_grad로 묶어준다.\n",
        "    with torch.no_grad():\n",
        "      # 이 때 data와 label 또한 GPU로 넘겨주어야 한다.\n",
        "      data = data.to(device)\n",
        "      label = label.to(device)\n",
        "          \n",
        "      # mobilenetv2 모델에 data를 넣어 추측(predict) 한다.\n",
        "      predict = net(data).to(device)\n",
        "      \n",
        "      # 학습 중 batch_size의 accuracy가 보고싶다면 printable=True 를 설정하세요.\n",
        "      temp_acc = accuracy(predict, label)\n",
        "      total_acc.append(temp_acc)\n",
        "      \n",
        "      # loss의 경우 추측값과 정답값을 비교한다.\n",
        "      loss = CEloss(predict, label)\n",
        "      total_loss.append(loss)\n",
        "      \n",
        "      # optimizer를 step 하는 것을 통해 optimizer에 선언한 parameter들을 학습시킨다.\n",
        "  print(\"\\n\")\n",
        "  print(f\"Test loss : {np.array(total_loss).sum() / len(total_loss)}\")\n",
        "  print(f\"Test accuracy : {np.array(total_acc).sum() / len(total_acc)}\")\n",
        "  print(f\"1 epoch time : {time.time() -start_time} (s)\")\n",
        "  print(\"\\n\")  \n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lP6BIkql5tP"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MQd0F7GKqNy"
      },
      "source": [
        "# loss 는 내가 네트워크를 어떠한 평가함수로 학습시키고 싶은지에 대한 함수이다.\n",
        "# classification의 경우 대부분 cross-entropy loss 를 사용한다.\n",
        "# https://darkpgmr.tistory.com/186 loss에 대한 대략적인 설명\n",
        "CEloss = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer는 loss.backward() 를 통해 얻은 gradient를 가지고 어떤 방식으로 학습시킬지에 대한 function 이다.\n",
        "# https://ganghee-lee.tistory.com/24 optimizer에 대한 대략적인 설명\n",
        "# https://pytorch.org/docs/stable/generated/torch.optim.SGD.html  torch.optim.sgd 에 대한 설명\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
        "\n",
        "\n",
        "def train(net, CEloss, train_loader, optimizer, scheduler, test_loader=False, epochs=20, validate_check=False):\n",
        "  # GPU를 사용하는지 안 하는지에 대한 확인 만약 CPU로 되어있을 경우 colab runtime 세션관리 에서 GPU 로 변경해두어야 함.\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  print(\"device : \", device)\n",
        "  assert device == \"cuda\"\n",
        "  # network를 device type 으로 변경\n",
        "  net.to(device)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    global_epoch = epoch\n",
        "    \n",
        "    total_acc = []\n",
        "    total_loss = []\n",
        "    start_time = time.time()\n",
        "    print(f\"{epoch} epcoh start\")\n",
        "    for data, label in tqdm(train_loader):\n",
        "      # 이 때 data와 label 또한 GPU로 넘겨주어야 한다.\n",
        "      data = data.to(device)\n",
        "      label = label.to(device)\n",
        "      \n",
        "      # optimizer 에 쓰레기값이 남아있지 않게 zero_grad()를 통해 초기화 시켜준다.\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      # resnet12 모델에 data를 넣어 추측(predict) 한다.\n",
        "      predict = net(data).to(device)\n",
        "      \n",
        "      # 학습 중 batch_size의 accuracy가 보고싶다면 printable=True 를 설정하세요.\n",
        "      temp_acc = accuracy(predict, label)\n",
        "      total_acc.append(temp_acc)\n",
        "      \n",
        "      # loss의 경우 추측값과 정답값을 비교한다.\n",
        "      loss = CEloss(predict, label)\n",
        "      total_loss.append(loss)\n",
        "      \n",
        "      # loss를 backward 시키는 것을 통해 네트워크의 trainable parameter에 대해 gradient를 구한다.\n",
        "      loss.backward()\n",
        "      \n",
        "      # optimizer를 step 하는 것을 통해 optimizer에 선언한 parameter들을 학습시킨다.\n",
        "      optimizer.step()\n",
        "    # scheduler를 통한 lr 감소 확인\n",
        "    scheduler.step()\n",
        "    print(\"\\n\")\n",
        "    print(f\"lr : {scheduler.get_last_lr()}\")\n",
        "    print(f\"{epoch} epcoh loss : {np.array(total_loss).sum() / len(total_loss)}\")\n",
        "    print(f\"{epoch} epcoh train accuracy : {np.array(total_acc).sum() / len(total_acc)}\")\n",
        "    print(f\"{epoch} epcoh time : {time.time() -start_time} (s)\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "    # 5번 마다 검증\n",
        "    if epoch % 5 == 0: \n",
        "      if validate_check == True and test_loader != False:\n",
        "        print(\"===============================\")\n",
        "        print(f\"{epoch} epcoh valid\")\n",
        "        validate(net, CEloss, test_loader)\n",
        "        print(\"===============================\")\n",
        "\n",
        "        # 검증 때마다 모델 출력\n",
        "        temp = epoch\n",
        "        temp = str(temp)\n",
        "        location = drive_path+\"06_SEResNet_model_epoch_\"+temp+\".pth\"\n",
        "        torch.save(net.state_dict(), location)\n",
        "    \n",
        "  # 학습 완료된 후 validation check \n",
        "  if validate_check == True and test_loader != False:\n",
        "      print(\"===============================\")\n",
        "      print(f\"{epochs} epcoh valid\")\n",
        "      validate(net, CEloss, test_loader)\n",
        "      print(\"===============================\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dTnSu9wmByv"
      },
      "source": [
        "# Start"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHiBMvLiMV14"
      },
      "source": [
        "train(net, CEloss, train_loader, optimizer, scheduler, test_loader, epochs=100, validate_check=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY9QV99PKw5N"
      },
      "source": [
        "# Network Parmeter Backup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1NZt0Eh9qIR"
      },
      "source": [
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "drive_path = \"/content/drive/MyDrive/Colab_Notebooks/pruning_result/\"\n",
        "'''"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zb_eezMepQp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hdDgGGRgagK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}